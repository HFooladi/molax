{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"molax","text":"<p>High-performance molecular active learning with JAX.</p> <p>molax provides GPU-accelerated active learning for molecular property prediction, using jraph for efficient graph batching (~400x speedup over naive implementations).</p>"},{"location":"index.html#features","title":"Features","text":"<ul> <li>Multiple uncertainty methods: MC Dropout, Deep Ensembles, Evidential Deep Learning</li> <li>Calibration metrics: Expected Calibration Error, calibration curves, reliability diagrams</li> <li>Acquisition functions: Uncertainty sampling, diversity sampling, combined strategies</li> <li>GPU-accelerated: Full JAX/Flax NNX integration with JIT compilation</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<p>Using uv (recommended):</p> <pre><code>git clone https://github.com/HFooladi/molax.git\ncd molax\nuv pip install -e .\n</code></pre> <p>For development:</p> <pre><code>uv pip install -e .[dev]\n</code></pre>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<pre><code>from molax.utils.data import MolecularDataset\nfrom molax.models.gcn import GCNConfig, UncertaintyGCN\nfrom flax import nnx\nimport jraph\nimport jax.numpy as jnp\n\n# Load dataset\ndataset = MolecularDataset('datasets/esol.csv')\ntrain_data, test_data = dataset.split(test_size=0.2, seed=42)\n\n# Batch all data once (key for performance!)\ntrain_graphs = jraph.batch(train_data.graphs)\ntrain_labels = jnp.array(train_data.labels)\n\n# Create model with uncertainty quantification\nconfig = GCNConfig(\n    node_features=6,\n    hidden_features=[64, 64],\n    out_features=1,\n    dropout_rate=0.1,\n)\nmodel = UncertaintyGCN(config, rngs=nnx.Rngs(0))\n\n# Get predictions with uncertainty\nmean, variance = model(train_graphs, training=True)\n</code></pre>"},{"location":"index.html#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts: Learn the batch-once-then-mask pattern that enables the 400x speedup</li> <li>API Reference: Detailed documentation of all models and functions</li> <li>Roadmap: See what's coming next</li> </ul>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see our GitHub repository for more information.</p>"},{"location":"index.html#license","title":"License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"concepts.html","title":"Core Concepts","text":"<p>This page explains the key concepts and architecture patterns in molax.</p>"},{"location":"concepts.html#performance-batch-once-then-mask","title":"Performance: Batch-Once-Then-Mask","text":"<p>The single most important optimization in molax is the batch-once-then-mask pattern. This achieves ~400x speedup over naive implementations.</p>"},{"location":"concepts.html#why-this-matters","title":"Why This Matters","text":"<p>JAX compiles functions with <code>@jit</code> based on array shapes. If shapes change between calls, JAX recompiles the function\u2014which is slow.</p> <pre><code># BAD - Different shapes trigger recompilation every time\nfor indices in batches:\n    batch = jraph.batch([graphs[i] for i in indices])  # Different shapes!\n    train_step(model, batch)  # Recompiles every time!\n</code></pre>"},{"location":"concepts.html#the-solution-pre-batch-masking","title":"The Solution: Pre-batch + Masking","text":"<p>Batch all data once upfront, then use boolean masks to select which samples contribute to the loss:</p> <pre><code>import jax.numpy as jnp\nimport jraph\nfrom flax import nnx\n\n# Batch ALL training data once at the start\nall_graphs = jraph.batch(train_data.graphs)\nall_labels = jnp.array(train_data.labels)\n\n# Use a mask to track which samples are labeled\nlabeled_mask = jnp.zeros(len(train_data), dtype=bool)\nlabeled_mask = labeled_mask.at[:50].set(True)  # Start with 50 labeled\n\n@nnx.jit\ndef train_step(model, optimizer, mask):\n    def loss_fn(model):\n        mean, var = model(all_graphs, training=True)\n        # Negative log-likelihood loss\n        nll = 0.5 * (jnp.log(var) + (all_labels - mean) ** 2 / var)\n        # Only count loss for labeled samples\n        return jnp.sum(jnp.where(mask, nll, 0.0)) / jnp.sum(mask)\n\n    loss, grads = nnx.value_and_grad(loss_fn)(model)\n    optimizer.update(model, grads)\n    return loss\n\n# Training loop - no recompilation!\nfor epoch in range(100):\n    loss = train_step(model, optimizer, labeled_mask)\n</code></pre> <p>When you acquire new samples, simply update the mask:</p> <pre><code># After acquiring new samples\nnew_indices = acquisition_function(model, unlabeled_indices)\nlabeled_mask = labeled_mask.at[new_indices].set(True)\n# train_step still uses the same shapes - no recompilation!\n</code></pre>"},{"location":"concepts.html#data-flow","title":"Data Flow","text":"<p>Understanding how data flows through molax:</p> <pre><code>SMILES string (e.g., \"CCO\")\n    \u2193 smiles_to_jraph()\njraph.GraphsTuple (single molecule graph)\n    - nodes: atom features [n_atoms, n_features]\n    - edges: bond features [n_bonds, n_features]\n    - senders/receivers: connectivity\n    \u2193 jraph.batch()\njraph.GraphsTuple (batched - all molecules as one big graph)\n    - nodes: [total_atoms, n_features]\n    - n_node: [n_molecules] - atoms per molecule\n    - n_edge: [n_molecules] - bonds per molecule\n    \u2193 UncertaintyGCN / DeepEnsemble / EvidentialGCN\n(mean, variance) predictions per molecule\n</code></pre>"},{"location":"concepts.html#example-loading-data","title":"Example: Loading Data","text":"<pre><code>from molax.utils.data import MolecularDataset\n\n# Load dataset\ndataset = MolecularDataset('datasets/esol.csv')\ntrain_data, test_data = dataset.split(test_size=0.2, seed=42)\n\n# Batch for training (do this once!)\nimport jraph\ntrain_graphs = jraph.batch(train_data.graphs)\ntrain_labels = jnp.array(train_data.labels)\n</code></pre>"},{"location":"concepts.html#uncertainty-types","title":"Uncertainty Types","text":"<p>molax distinguishes between two types of uncertainty:</p>"},{"location":"concepts.html#epistemic-uncertainty-model-uncertainty","title":"Epistemic Uncertainty (Model Uncertainty)","text":"<ul> <li>What: Uncertainty due to lack of knowledge/data</li> <li>Behavior: Decreases with more training data</li> <li>Use case: Active learning - select samples where model is uncertain</li> <li>Measured by:</li> <li>MC Dropout variance</li> <li>Ensemble disagreement</li> <li>Evidential epistemic uncertainty</li> </ul>"},{"location":"concepts.html#aleatoric-uncertainty-data-uncertainty","title":"Aleatoric Uncertainty (Data Uncertainty)","text":"<ul> <li>What: Inherent noise in the data</li> <li>Behavior: Cannot be reduced by more data</li> <li>Use case: Understanding data quality, heteroscedastic regression</li> <li>Measured by:</li> <li>Predicted variance head</li> <li>Evidential aleatoric uncertainty</li> </ul>"},{"location":"concepts.html#why-this-matters-for-active-learning","title":"Why This Matters for Active Learning","text":"<p>For active learning, you typically want to select samples with high epistemic uncertainty\u2014these are the samples where acquiring labels will most improve the model. High aleatoric uncertainty indicates noisy data points that won't help much.</p> <pre><code># Deep Ensemble separates the two uncertainties\nensemble = DeepEnsemble(config, n_members=5, rngs=nnx.Rngs(0))\nmean, epistemic_var, aleatoric_var = ensemble(graphs, training=False)\n\n# Use epistemic uncertainty for acquisition\nscores = epistemic_var  # High = model is uncertain\n</code></pre>"},{"location":"concepts.html#choosing-a-model","title":"Choosing a Model","text":"<p>molax provides three approaches to uncertainty quantification:</p>"},{"location":"concepts.html#mc-dropout-uncertaintygcn","title":"MC Dropout (<code>UncertaintyGCN</code>)","text":"<p>Best for: Quick prototyping, limited compute</p> <pre><code>from molax.models.gcn import GCNConfig, UncertaintyGCN\n\nconfig = GCNConfig(\n    node_features=6,\n    hidden_features=[64, 64],\n    out_features=1,\n    dropout_rate=0.1,\n)\nmodel = UncertaintyGCN(config, rngs=nnx.Rngs(0))\n\n# Get uncertainty via multiple forward passes\nmean, var = model(graphs, training=True)  # training=True enables dropout\n</code></pre> <p>Pros: Single model, fast training, no extra memory Cons: Uncertainty estimates can be poorly calibrated</p>"},{"location":"concepts.html#deep-ensembles-deepensemble","title":"Deep Ensembles (<code>DeepEnsemble</code>)","text":"<p>Best for: Production use, well-calibrated uncertainty</p> <pre><code>from molax.models.ensemble import EnsembleConfig, DeepEnsemble\n\nconfig = EnsembleConfig(\n    node_features=6,\n    hidden_features=[64, 64],\n    out_features=1,\n    n_members=5,\n)\nensemble = DeepEnsemble(config, rngs=nnx.Rngs(0))\n\nmean, epistemic_var, aleatoric_var = ensemble(graphs, training=False)\n</code></pre> <p>Pros: Best calibration, separate epistemic/aleatoric, robust Cons: N\u00d7 training time and memory</p>"},{"location":"concepts.html#evidential-deep-learning-evidentialgcn","title":"Evidential Deep Learning (<code>EvidentialGCN</code>)","text":"<p>Best for: Single-pass uncertainty, out-of-distribution detection</p> <pre><code>from molax.models.evidential import EvidentialConfig, EvidentialGCN\n\nconfig = EvidentialConfig(\n    node_features=6,\n    hidden_features=[64, 64],\n    out_features=1,\n)\nmodel = EvidentialGCN(config, rngs=nnx.Rngs(0))\n\nmean, aleatoric_var, epistemic_var = model(graphs, training=False)\n</code></pre> <p>Pros: Single forward pass, explicit uncertainty decomposition Cons: Requires careful loss tuning, can be overconfident</p>"},{"location":"concepts.html#calibration","title":"Calibration","text":"<p>Well-calibrated uncertainty means the model's confidence matches its accuracy. molax provides tools to measure and visualize calibration:</p> <pre><code>from molax.metrics import expected_calibration_error, calibration_report\nfrom molax.metrics.visualization import plot_calibration_curve\n\n# Compute ECE\nece = expected_calibration_error(predictions, variances, targets)\nprint(f\"Expected Calibration Error: {ece:.4f}\")\n\n# Generate full report\nreport = calibration_report(predictions, variances, targets)\n\n# Visualize\nfig = plot_calibration_curve(predictions, variances, targets)\nfig.savefig(\"calibration.png\")\n</code></pre> <p>A perfectly calibrated model has ECE = 0. In practice, ECE &lt; 0.05 is considered well-calibrated.</p>"},{"location":"roadmap.html","title":"Molax Feature Roadmap","text":"<p>A prioritized roadmap of killer features for molax, focusing on advancing uncertainty quantification for molecular active learning.</p> <p>Target Audiences: - Drug discovery researchers seeking reliable predictions with confidence estimates - ML researchers exploring uncertainty quantification and active learning methods</p> <p>Scope: 2D graph-based molecular representations only (no 3D conformers).</p>"},{"location":"roadmap.html#current-capabilities","title":"Current Capabilities","text":"Feature Status Efficient jraph batching (~400x speedup) \u2705 GCN with uncertainty head \u2705 MC Dropout uncertainty \u2705 Uncertainty sampling \u2705 Diversity sampling \u2705 Combined acquisition \u2705 ESOL dataset support \u2705 Flax NNX integration \u2705"},{"location":"roadmap.html#phase-1-uncertainty-excellence-high-priority","title":"Phase 1: Uncertainty Excellence (High Priority)","text":"<p>Better uncertainty quantification is the core differentiator for active learning. These features directly improve the quality and reliability of uncertainty estimates.</p>"},{"location":"roadmap.html#11-deep-ensembles","title":"1.1 Deep Ensembles \u2705","text":"<p>Status: Implemented in <code>molax/models/ensemble.py</code></p> <p>What: Train N independent GCN models with different random initializations; use prediction disagreement as uncertainty.</p> <p>Why: Ensembles consistently outperform single-model uncertainty methods. They capture both aleatoric (data) and epistemic (model) uncertainty.</p> <p>Implementation:</p> <pre><code># molax/models/ensemble.py\nfrom dataclasses import dataclass\nfrom flax import nnx\nimport jax.numpy as jnp\nfrom molax.models.gcn import GCNConfig, UncertaintyGCN\n\n@dataclass\nclass EnsembleConfig:\n    base_config: GCNConfig\n    n_members: int = 5\n\nclass DeepEnsemble(nnx.Module):\n    def __init__(self, config: EnsembleConfig, rngs: nnx.Rngs):\n        self.members = [\n            UncertaintyGCN(config.base_config, rngs=nnx.Rngs(i))\n            for i in range(config.n_members)\n        ]\n\n    def __call__(self, graphs, training: bool = False):\n        # Collect predictions from all members\n        predictions = [m(graphs, training=training) for m in self.members]\n        means = jnp.stack([p[0] for p in predictions])  # (N, batch)\n\n        # Ensemble mean and variance\n        ensemble_mean = jnp.mean(means, axis=0)\n        epistemic_var = jnp.var(means, axis=0)  # Disagreement\n        aleatoric_var = jnp.mean(jnp.stack([p[1] for p in predictions]), axis=0)\n        total_var = epistemic_var + aleatoric_var\n\n        return ensemble_mean, total_var, epistemic_var\n</code></pre> <p>Acceptance Criteria: - [x] <code>DeepEnsemble</code> class with configurable number of members - [x] Separate epistemic and aleatoric uncertainty outputs - [x] Parallel training support for ensemble members - [x] Tests comparing ensemble vs MC Dropout uncertainty quality</p>"},{"location":"roadmap.html#12-evidential-deep-learning","title":"1.2 Evidential Deep Learning \u2705","text":"<p>Status: Implemented in <code>molax/models/evidential.py</code></p> <p>What: Directly predict uncertainty without MC sampling by modeling output as a higher-order distribution (Normal-Inverse-Gamma).</p> <p>Why: Single forward pass for uncertainty (faster inference), well-calibrated for out-of-distribution detection.</p> <p>Reference: Amini et al., NeurIPS 2020</p> <p>Implementation:</p> <pre><code># molax/models/evidential.py\nimport jax.numpy as jnp\nfrom flax import nnx\n\nclass EvidentialHead(nnx.Module):\n    \"\"\"Predicts Normal-Inverse-Gamma parameters for evidential regression.\"\"\"\n\n    def __init__(self, in_features: int, rngs: nnx.Rngs):\n        # Output: (gamma, nu, alpha, beta) - NIG parameters\n        self.linear = nnx.Linear(in_features, 4, rngs=rngs)\n\n    def __call__(self, x):\n        out = self.linear(x)\n        # Ensure valid parameter ranges\n        gamma = out[..., 0]  # Mean prediction\n        nu = nnx.softplus(out[..., 1]) + 1e-6  # &gt; 0\n        alpha = nnx.softplus(out[..., 2]) + 1.0  # &gt; 1\n        beta = nnx.softplus(out[..., 3]) + 1e-6  # &gt; 0\n        return gamma, nu, alpha, beta\n\ndef evidential_loss(gamma, nu, alpha, beta, targets, lambda_reg=0.1):\n    \"\"\"NIG negative log-likelihood with regularization.\"\"\"\n    omega = 2 * beta * (1 + nu)\n    nll = (\n        0.5 * jnp.log(jnp.pi / nu)\n        - alpha * jnp.log(omega)\n        + (alpha + 0.5) * jnp.log((targets - gamma)**2 * nu + omega)\n        + jnp.lgamma(alpha) - jnp.lgamma(alpha + 0.5)\n    )\n    # Regularize evidence on errors\n    reg = lambda_reg * jnp.abs(targets - gamma) * (2 * nu + alpha)\n    return jnp.mean(nll + reg)\n\ndef evidential_uncertainty(nu, alpha, beta):\n    \"\"\"Extract aleatoric and epistemic uncertainty from NIG params.\"\"\"\n    aleatoric = beta / (alpha - 1)  # Expected variance\n    epistemic = aleatoric / nu      # Uncertainty in the variance\n    return aleatoric, epistemic\n</code></pre> <p>Acceptance Criteria: - [x] <code>EvidentialGCN</code> model variant - [x] NIG loss function with configurable regularization - [x] Separate aleatoric/epistemic uncertainty outputs - [x] Comparison with MC Dropout on OOD detection (in tests)</p>"},{"location":"roadmap.html#13-calibration-metrics","title":"1.3 Calibration Metrics \u2705","text":"<p>Status: Implemented in <code>molax/metrics/</code></p> <p>What: Quantify how well predicted uncertainties match actual error frequencies.</p> <p>Why: Raw uncertainties are meaningless without calibration. These metrics let users trust the confidence estimates.</p> <p>Implementation:</p> <pre><code># molax/metrics/calibration.py\nfrom molax.metrics import (\n    expected_calibration_error,\n    negative_log_likelihood,\n    compute_calibration_curve,\n    sharpness,\n    evaluate_calibration,\n    TemperatureScaling,\n    plot_reliability_diagram,\n    plot_calibration_comparison,\n    create_calibration_report,\n)\n\n# Compute ECE\nece = expected_calibration_error(predictions, uncertainties, targets, n_bins=10)\n\n# Compute NLL (proper scoring rule)\nnll = negative_log_likelihood(mean, var, targets)\n\n# Comprehensive evaluation\nmetrics = evaluate_calibration(mean, var, targets)\n# Returns: {'nll': ..., 'ece': ..., 'rmse': ..., 'sharpness': ..., 'mean_z_score': ...}\n\n# Temperature scaling for post-hoc calibration\nscaler = TemperatureScaling()\nscaler.fit(val_mean, val_var, val_targets)\ncalibrated_var = scaler.transform(test_var)\nprint(f\"Learned temperature: {scaler.temperature}\")\n\n# Visualization\nplot_reliability_diagram(predictions, uncertainties, targets)\nfig = plot_calibration_comparison({\n    \"Model A\": (preds_a, var_a, targets),\n    \"Model B\": (preds_b, var_b, targets),\n})\n</code></pre> <p>Acceptance Criteria: - [x] ECE computation (Expected Calibration Error) - [x] Reliability diagram plotting utility - [x] NLL as proper scoring rule - [x] Temperature scaling for post-hoc calibration - [x] Integration into evaluation pipeline</p>"},{"location":"roadmap.html#phase-2-advanced-acquisition-strategies","title":"Phase 2: Advanced Acquisition Strategies","text":"<p>Better acquisition functions select more informative samples, improving data efficiency.</p>"},{"location":"roadmap.html#21-bald-bayesian-active-learning-by-disagreement","title":"2.1 BALD (Bayesian Active Learning by Disagreement)","text":"<p>What: Maximize mutual information between predictions and model parameters.</p> <p>Why: Theoretically principled; targets samples that maximally reduce model uncertainty.</p> <p>Implementation:</p> <pre><code># molax/acquisition/bald.py\nimport jax.numpy as jnp\n\ndef bald_acquisition(\n    model,\n    graphs,\n    n_mc_samples: int = 20,\n    rngs: jnp.ndarray = None\n) -&gt; jnp.ndarray:\n    \"\"\"\n    BALD = H[y|x, D] - E_{theta}[H[y|x, theta]]\n    = Total uncertainty - Expected aleatoric uncertainty\n    \"\"\"\n    # Collect MC samples\n    mc_means = []\n    mc_vars = []\n    for i in range(n_mc_samples):\n        mean, var = model(graphs, training=True)  # Dropout active\n        mc_means.append(mean)\n        mc_vars.append(var)\n\n    mc_means = jnp.stack(mc_means)  # (n_mc, n_samples)\n    mc_vars = jnp.stack(mc_vars)\n\n    # Total uncertainty (entropy of predictive distribution)\n    predictive_mean = jnp.mean(mc_means, axis=0)\n    predictive_var = jnp.var(mc_means, axis=0) + jnp.mean(mc_vars, axis=0)\n    total_entropy = 0.5 * jnp.log(2 * jnp.pi * jnp.e * predictive_var)\n\n    # Expected aleatoric uncertainty\n    expected_entropy = 0.5 * jnp.mean(jnp.log(2 * jnp.pi * jnp.e * mc_vars), axis=0)\n\n    # BALD score = mutual information\n    return total_entropy - expected_entropy\n</code></pre> <p>Acceptance Criteria: - [ ] <code>bald_acquisition</code> function - [ ] Efficient batched MC sampling - [ ] Comparison benchmark vs uncertainty sampling</p>"},{"location":"roadmap.html#22-core-set-selection","title":"2.2 Core-Set Selection","text":"<p>What: Select samples that maximize coverage of the feature space using K-center algorithm.</p> <p>Why: Ensures diversity in learned representations, not just input space.</p> <p>Implementation:</p> <pre><code># molax/acquisition/coreset.py\nimport jax.numpy as jnp\n\ndef extract_embeddings(model, graphs) -&gt; jnp.ndarray:\n    \"\"\"Get penultimate layer representations.\"\"\"\n    # Add embedding extraction hook to model\n    pass\n\ndef k_center_greedy(\n    embeddings: jnp.ndarray,\n    labeled_mask: jnp.ndarray,\n    n_select: int\n) -&gt; jnp.ndarray:\n    \"\"\"\n    Greedy K-center: iteratively select point furthest from labeled set.\n    \"\"\"\n    n_samples = embeddings.shape[0]\n    selected = jnp.where(labeled_mask)[0]\n\n    # Compute pairwise distances once\n    distances = jnp.linalg.norm(\n        embeddings[:, None] - embeddings[None, :], axis=-1\n    )\n\n    for _ in range(n_select):\n        # Distance from each point to nearest labeled point\n        min_dist_to_labeled = jnp.min(distances[:, selected], axis=1)\n        min_dist_to_labeled = jnp.where(labeled_mask, -jnp.inf, min_dist_to_labeled)\n\n        # Select furthest point\n        new_idx = jnp.argmax(min_dist_to_labeled)\n        selected = jnp.append(selected, new_idx)\n        labeled_mask = labeled_mask.at[new_idx].set(True)\n\n    return selected[-n_select:]\n</code></pre> <p>Acceptance Criteria: - [ ] Embedding extraction from any model layer - [ ] K-center greedy implementation - [ ] GPU-accelerated distance computations</p>"},{"location":"roadmap.html#23-batch-aware-acquisition","title":"2.3 Batch-Aware Acquisition","text":"<p>What: When selecting K samples, account for redundancy between them.</p> <p>Why: Naive top-K selection often picks near-duplicates; batch-aware methods improve diversity.</p> <p>Implementation:</p> <pre><code># molax/acquisition/batch.py\n\ndef batch_bald(\n    model, graphs, n_select: int, n_mc_samples: int = 20\n) -&gt; jnp.ndarray:\n    \"\"\"\n    BatchBALD: Select batch jointly to maximize mutual information.\n    Approximated via greedy selection with joint entropy tracking.\n    \"\"\"\n    pass\n\ndef determinantal_point_process(\n    scores: jnp.ndarray,\n    similarity_matrix: jnp.ndarray,\n    n_select: int\n) -&gt; jnp.ndarray:\n    \"\"\"\n    DPP sampling: balance high scores with diversity.\n    Uses fast greedy MAP inference.\n    \"\"\"\n    pass\n</code></pre> <p>Acceptance Criteria: - [ ] BatchBALD implementation - [ ] DPP-based diverse selection - [ ] Configurable diversity-quality tradeoff</p>"},{"location":"roadmap.html#24-expected-model-change","title":"2.4 Expected Model Change","text":"<p>What: Select samples that would maximally change model predictions if labeled.</p> <p>Why: Directly targets samples that affect the model most, regardless of current uncertainty.</p> <p>Implementation:</p> <pre><code># molax/acquisition/emc.py\n\ndef expected_gradient_length(model, graphs, labels_placeholder):\n    \"\"\"\n    EGL: Use gradient magnitude as proxy for influence.\n    \"\"\"\n    def loss_fn(model, x, y):\n        mean, _ = model(x, training=False)\n        return jnp.mean((mean - y)**2)\n\n    # Compute gradient for hypothetical labels (use predicted mean)\n    predicted_mean, _ = model(graphs, training=False)\n    grads = jax.grad(loss_fn)(model, graphs, predicted_mean)\n\n    # Gradient magnitude per sample\n    return jnp.linalg.norm(grads, axis=-1)\n</code></pre> <p>Acceptance Criteria: - [ ] Expected Gradient Length implementation - [ ] Fisher Information-based variant - [ ] Efficient gradient computation</p>"},{"location":"roadmap.html#phase-3-architecture-diversity","title":"Phase 3: Architecture Diversity","text":"<p>Multiple architectures capture different inductive biases about molecular structure.</p>"},{"location":"roadmap.html#31-message-passing-neural-network-mpnn","title":"3.1 Message Passing Neural Network (MPNN) \u2705","text":"<p>Status: Implemented in <code>molax/models/mpnn.py</code></p> <p>What: Generalized framework with explicit edge feature processing.</p> <p>Why: Enables richer molecular representations using bond features.</p> <p>Implementation:</p> <pre><code># molax/models/mpnn.py\nfrom molax.models.mpnn import MPNNConfig, UncertaintyMPNN\n\nconfig = MPNNConfig(\n    node_features=6,\n    edge_features=1,  # Bond type feature\n    hidden_features=[64, 64],\n    out_features=1,\n    aggregation=\"sum\",  # or \"mean\", \"max\"\n    dropout_rate=0.1,\n)\nmodel = UncertaintyMPNN(config, rngs=nnx.Rngs(0))\n\n# Same API as UncertaintyGCN\nmean, variance = model(batched_graphs, training=False)\n\n# Extract embeddings for Core-Set selection\nembeddings = model.extract_embeddings(batched_graphs)\n</code></pre> <p>Acceptance Criteria: - [x] MPNN with edge feature support - [x] Configurable aggregation (sum, mean, max) - [x] Same API as UncertaintyGCN for acquisition function compatibility - [x] MC Dropout uncertainty via <code>get_mpnn_uncertainties()</code></p>"},{"location":"roadmap.html#32-graph-attention-network-gat","title":"3.2 Graph Attention Network (GAT) \u2705","text":"<p>Status: Implemented in <code>molax/models/gat.py</code></p> <p>What: Learn edge importance dynamically via attention mechanism.</p> <p>Why: Adaptively weights neighbor contributions based on learned relevance.</p> <p>Implementation:</p> <pre><code># molax/models/gat.py\nfrom molax.models.gat import GATConfig, UncertaintyGAT\n\nconfig = GATConfig(\n    node_features=6,\n    edge_features=1,  # Optional: include edge features in attention\n    hidden_features=[64, 64],\n    out_features=1,\n    n_heads=4,\n    dropout_rate=0.1,\n    attention_dropout_rate=0.1,\n    negative_slope=0.2,\n)\nmodel = UncertaintyGAT(config, rngs=nnx.Rngs(0))\n\n# Same API as UncertaintyGCN/UncertaintyMPNN\nmean, variance = model(batched_graphs, training=False)\n\n# Extract embeddings for Core-Set selection\nembeddings = model.extract_embeddings(batched_graphs)\n</code></pre> <p>Acceptance Criteria: - [x] Multi-head attention implementation - [x] Edge feature incorporation option - [x] Dropout on attention weights - [x] Same API as UncertaintyGCN/UncertaintyMPNN for acquisition function compatibility</p>"},{"location":"roadmap.html#33-schnet-continuous-filter-convolutions","title":"3.3 SchNet (Continuous-Filter Convolutions)","text":"<p>What: Distance-based convolutions using RBF expansions (adapted for 2D without coordinates).</p> <p>Why: Smooth distance-aware aggregation; useful when edge weights encode bond lengths.</p> <p>Note: For 2D graphs, use topological distance (shortest path) or bond order as edge weights.</p>"},{"location":"roadmap.html#34-graph-transformer","title":"3.4 Graph Transformer","text":"<p>What: Full self-attention over molecular graphs with positional encodings.</p> <p>Why: State-of-the-art performance; captures long-range dependencies.</p> <p>Implementation:</p> <pre><code># molax/models/graph_transformer.py\n\nclass GraphTransformerLayer(nnx.Module):\n    def __init__(self, d_model, n_heads, rngs):\n        self.attention = nnx.MultiHeadAttention(\n            num_heads=n_heads,\n            in_features=d_model,\n            rngs=rngs\n        )\n        self.ff = nnx.Sequential([\n            nnx.Linear(d_model, 4 * d_model, rngs=rngs),\n            nnx.gelu,\n            nnx.Linear(4 * d_model, d_model, rngs=rngs),\n        ])\n        self.norm1 = nnx.LayerNorm(d_model, rngs=rngs)\n        self.norm2 = nnx.LayerNorm(d_model, rngs=rngs)\n\n    def __call__(self, nodes, attention_mask):\n        # Self-attention with graph structure mask\n        attn_out = self.attention(nodes, nodes, mask=attention_mask)\n        nodes = self.norm1(nodes + attn_out)\n        nodes = self.norm2(nodes + self.ff(nodes))\n        return nodes\n</code></pre> <p>Acceptance Criteria: - [ ] Graph-aware attention masking - [ ] Positional encodings (Laplacian eigenvectors, random walk) - [ ] Configurable depth and width</p>"},{"location":"roadmap.html#phase-4-rich-molecular-featurization","title":"Phase 4: Rich Molecular Featurization","text":"<p>Better input features directly improve model capacity.</p>"},{"location":"roadmap.html#41-extended-node-features","title":"4.1 Extended Node Features","text":"<p>Current: 6 features (atomic num, degree, charge, chirality, hybridization, aromaticity)</p> <p>Proposed: 20+ features including:</p> <pre><code># molax/utils/featurizers.py\n\ndef extended_atom_features(atom) -&gt; list:\n    \"\"\"Comprehensive RDKit atom features.\"\"\"\n    return [\n        # Current features\n        atom.GetAtomicNum(),\n        atom.GetDegree(),\n        atom.GetFormalCharge(),\n        int(atom.GetChiralTag()),\n        int(atom.GetHybridization()),\n        int(atom.GetIsAromatic()),\n\n        # Ring features\n        atom.IsInRing(),\n        atom.IsInRingSize(3),\n        atom.IsInRingSize(4),\n        atom.IsInRingSize(5),\n        atom.IsInRingSize(6),\n\n        # Electronic features\n        atom.GetNumRadicalElectrons(),\n        atom.GetNumImplicitHs(),\n        atom.GetNumExplicitHs(),\n\n        # Neighborhood\n        atom.GetTotalNumHs(),\n        atom.GetTotalDegree(),\n\n        # Pharmacophore-related\n        is_hydrogen_donor(atom),\n        is_hydrogen_acceptor(atom),\n\n        # Electronegativity (from table)\n        ELECTRONEGATIVITY.get(atom.GetAtomicNum(), 0),\n\n        # Atomic mass\n        atom.GetMass(),\n    ]\n</code></pre> <p>Acceptance Criteria: - [ ] Configurable feature sets (minimal, standard, extended) - [ ] Feature normalization utilities - [ ] Documentation of each feature</p>"},{"location":"roadmap.html#42-edge-feature-support","title":"4.2 Edge Feature Support","text":"<p>What: Include bond features in message passing.</p> <pre><code>def bond_features(bond) -&gt; list:\n    \"\"\"RDKit bond features.\"\"\"\n    return [\n        int(bond.GetBondType()),  # Single, double, triple, aromatic\n        bond.GetIsConjugated(),\n        bond.IsInRing(),\n        int(bond.GetStereo()),  # Stereochemistry\n    ]\n</code></pre> <p>Acceptance Criteria: - [ ] Edge features in <code>smiles_to_jraph</code> - [ ] Models that consume edge features (MPNN, GAT)</p>"},{"location":"roadmap.html#43-pre-trained-embedding-integration","title":"4.3 Pre-trained Embedding Integration","text":"<p>What: Use embeddings from pre-trained molecular language models.</p> <p>Why: Transfer learning from large-scale pre-training.</p> <pre><code># molax/utils/pretrained.py\n\ndef load_chemberta_embeddings(smiles_list: list[str]) -&gt; jnp.ndarray:\n    \"\"\"Extract ChemBERTa [CLS] token embeddings.\"\"\"\n    from transformers import AutoModel, AutoTokenizer\n\n    tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n    model = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n\n    inputs = tokenizer(smiles_list, return_tensors=\"pt\", padding=True)\n    outputs = model(**inputs)\n    return jnp.array(outputs.last_hidden_state[:, 0, :])  # [CLS] token\n</code></pre> <p>Acceptance Criteria: - [ ] ChemBERTa integration - [ ] Caching for efficiency - [ ] Option to use as initial node features or auxiliary input</p>"},{"location":"roadmap.html#phase-5-production-readiness","title":"Phase 5: Production Readiness","text":"<p>Features required for real-world deployment.</p>"},{"location":"roadmap.html#51-model-checkpointing","title":"5.1 Model Checkpointing","text":"<p>What: Save and load model state.</p> <pre><code># molax/utils/checkpointing.py\nimport orbax.checkpoint as ocp\nfrom flax import nnx\n\ndef save_model(model, optimizer, path: str, step: int):\n    \"\"\"Save model and optimizer state.\"\"\"\n    state = nnx.state((model, optimizer))\n    checkpointer = ocp.PyTreeCheckpointer()\n    checkpointer.save(f\"{path}/step_{step}\", state)\n\ndef load_model(model, optimizer, path: str):\n    \"\"\"Restore model and optimizer state.\"\"\"\n    checkpointer = ocp.PyTreeCheckpointer()\n    state = checkpointer.restore(path)\n    nnx.update((model, optimizer), state)\n</code></pre> <p>Acceptance Criteria: - [ ] Orbax-based save/load - [ ] Checkpoint management (keep last N) - [ ] Resume training from checkpoint</p>"},{"location":"roadmap.html#52-multi-dataset-support","title":"5.2 Multi-Dataset Support","text":"<p>What: Support MoleculeNet benchmarks.</p> <pre><code># molax/datasets/moleculenet.py\n\nMOLECULENET_DATASETS = {\n    'esol': {'task': 'regression', 'n_tasks': 1, 'metric': 'rmse'},\n    'freesolv': {'task': 'regression', 'n_tasks': 1, 'metric': 'rmse'},\n    'lipophilicity': {'task': 'regression', 'n_tasks': 1, 'metric': 'rmse'},\n    'bbbp': {'task': 'classification', 'n_tasks': 1, 'metric': 'auroc'},\n    'tox21': {'task': 'classification', 'n_tasks': 12, 'metric': 'auroc'},\n    'sider': {'task': 'classification', 'n_tasks': 27, 'metric': 'auroc'},\n    'clintox': {'task': 'classification', 'n_tasks': 2, 'metric': 'auroc'},\n    'muv': {'task': 'classification', 'n_tasks': 17, 'metric': 'prc-auc'},\n    'hiv': {'task': 'classification', 'n_tasks': 1, 'metric': 'auroc'},\n    'bace': {'task': 'classification', 'n_tasks': 1, 'metric': 'auroc'},\n}\n\ndef load_moleculenet(name: str) -&gt; MolecularDataset:\n    \"\"\"Load a MoleculeNet dataset.\"\"\"\n    pass\n</code></pre> <p>Acceptance Criteria: - [ ] All MoleculeNet datasets supported - [ ] Scaffold and random split utilities - [ ] Classification task support</p>"},{"location":"roadmap.html#53-hyperparameter-optimization","title":"5.3 Hyperparameter Optimization","text":"<p>What: Automated hyperparameter tuning.</p> <pre><code># molax/tuning/optuna_search.py\nimport optuna\n\ndef create_objective(dataset, n_epochs):\n    def objective(trial):\n        config = GCNConfig(\n            hidden_features=[\n                trial.suggest_int('hidden_dim', 32, 256),\n            ] * trial.suggest_int('n_layers', 1, 4),\n            dropout_rate=trial.suggest_float('dropout', 0.0, 0.5),\n        )\n        # Train and evaluate\n        model = UncertaintyGCN(config, rngs=nnx.Rngs(0))\n        # ... training loop\n        return val_loss\n    return objective\n\ndef run_hpo(dataset, n_trials=100):\n    study = optuna.create_study(direction='minimize')\n    study.optimize(create_objective(dataset, n_epochs=50), n_trials=n_trials)\n    return study.best_params\n</code></pre> <p>Acceptance Criteria: - [ ] Optuna integration - [ ] Search space definitions for each model - [ ] Pruning for early stopping</p>"},{"location":"roadmap.html#54-experiment-tracking","title":"5.4 Experiment Tracking","text":"<p>What: Log metrics, hyperparameters, and artifacts.</p> <pre><code># molax/tracking/wandb_logger.py\nimport wandb\n\nclass WandbLogger:\n    def __init__(self, project: str, config: dict):\n        wandb.init(project=project, config=config)\n\n    def log(self, metrics: dict, step: int):\n        wandb.log(metrics, step=step)\n\n    def log_model(self, model_path: str):\n        wandb.save(model_path)\n</code></pre> <p>Acceptance Criteria: - [ ] W&amp;B integration - [ ] MLflow as alternative - [ ] Automatic logging in training loop</p>"},{"location":"roadmap.html#phase-6-advanced-ml-research","title":"Phase 6: Advanced ML Research","text":"<p>Features for ML researchers pushing the boundaries.</p>"},{"location":"roadmap.html#61-multi-task-learning","title":"6.1 Multi-Task Learning","text":"<p>What: Predict multiple properties with shared GNN backbone.</p> <pre><code>class MultiTaskGCN(nnx.Module):\n    def __init__(self, config, n_tasks, rngs):\n        self.backbone = GCNBackbone(config, rngs)\n        self.heads = [\n            UncertaintyHead(config.hidden_features[-1], rngs)\n            for _ in range(n_tasks)\n        ]\n\n    def __call__(self, graphs, training=False):\n        embeddings = self.backbone(graphs, training)\n        return [head(embeddings) for head in self.heads]\n</code></pre> <p>Acceptance Criteria: - [ ] Multi-head architecture - [ ] Task weighting strategies - [ ] Uncertainty per task</p>"},{"location":"roadmap.html#62-transfer-learning","title":"6.2 Transfer Learning","text":"<p>What: Pre-train on large dataset, fine-tune on small target dataset.</p> <p>Acceptance Criteria: - [ ] Backbone freezing/unfreezing - [ ] Learning rate schedules for fine-tuning - [ ] Pre-trained weights for common backbones</p>"},{"location":"roadmap.html#63-semi-supervised-learning","title":"6.3 Semi-Supervised Learning","text":"<p>What: Leverage unlabeled molecules to improve representations.</p> <pre><code>def consistency_loss(model, unlabeled_graphs, rngs):\n    \"\"\"Encourage consistent predictions under augmentation.\"\"\"\n    # Two forward passes with different dropout\n    pred1, _ = model(unlabeled_graphs, training=True)\n    pred2, _ = model(unlabeled_graphs, training=True)\n    return jnp.mean((pred1 - pred2)**2)\n</code></pre> <p>Acceptance Criteria: - [ ] Consistency regularization - [ ] Pseudo-labeling - [ ] Graph augmentation utilities</p>"},{"location":"roadmap.html#64-meta-learning-maml","title":"6.4 Meta-Learning (MAML)","text":"<p>What: Learn to adapt quickly to new molecular tasks with few examples.</p> <p>Why: Critical for low-data drug discovery scenarios.</p> <pre><code>def maml_inner_loop(model, support_graphs, support_labels, inner_lr, n_steps):\n    \"\"\"Adapt model to support set.\"\"\"\n    adapted_model = model.clone()  # Create copy\n\n    for _ in range(n_steps):\n        loss, grads = nnx.value_and_grad(loss_fn)(adapted_model, support_graphs, support_labels)\n        # Manual gradient descent\n        adapted_model = jax.tree_map(\n            lambda p, g: p - inner_lr * g,\n            adapted_model, grads\n        )\n\n    return adapted_model\n</code></pre> <p>Acceptance Criteria: - [ ] MAML implementation for few-shot property prediction - [ ] Task distribution utilities - [ ] First-order approximation option</p>"},{"location":"roadmap.html#implementation-priority","title":"Implementation Priority","text":"Phase Timeline Impact Effort 1. Uncertainty Excellence High High Medium 2. Advanced Acquisition High High Medium 3. Architecture Diversity Medium Medium High 4. Rich Featurization Medium Medium Low 5. Production Readiness Medium High Medium 6. Advanced ML Low Medium High"},{"location":"roadmap.html#contributing","title":"Contributing","text":"<p>We welcome contributions! Priority areas: 1. Uncertainty methods - Ensembles, evidential learning 2. Calibration tools - Metrics and visualization 3. Acquisition functions - BALD, batch-aware selection</p> <p>See CONTRIBUTING.md for guidelines.</p>"},{"location":"api/acquisition.html","title":"Acquisition Functions","text":"<p>This page documents the acquisition functions for active learning sample selection.</p>"},{"location":"api/acquisition.html#uncertainty-based-acquisition","title":"Uncertainty-based Acquisition","text":"<p>Functions that select samples based on model uncertainty.</p>"},{"location":"api/acquisition.html#uncertainty_sampling","title":"uncertainty_sampling","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.uncertainty_sampling","title":"molax.acquisition.uncertainty.uncertainty_sampling","text":"<pre><code>uncertainty_sampling(\n    model: UncertaintyGCN, pool_graphs: List[GraphsTuple], n_samples: int = 10\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute uncertainty scores for pool samples using MC dropout.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>UncertaintyGCN</code> <p>UncertaintyGCN model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of jraph.GraphsTuple for pool samples</p> required <code>n_samples</code> <code>int</code> <p>Number of MC dropout samples</p> <code>10</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of uncertainty scores for each pool sample</p>"},{"location":"api/acquisition.html#ensemble_uncertainty_sampling","title":"ensemble_uncertainty_sampling","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.ensemble_uncertainty_sampling","title":"molax.acquisition.uncertainty.ensemble_uncertainty_sampling","text":"<pre><code>ensemble_uncertainty_sampling(\n    ensemble: DeepEnsemble,\n    pool_graphs: List[GraphsTuple],\n    use_epistemic: bool = True,\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute uncertainty scores for pool samples using ensemble disagreement.</p> <p>Unlike MC Dropout, ensembles provide uncertainty in a single forward pass by measuring disagreement between independently trained models.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>DeepEnsemble</code> <p>DeepEnsemble model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of jraph.GraphsTuple for pool samples</p> required <code>use_epistemic</code> <code>bool</code> <p>If True, use epistemic uncertainty (model disagreement).           If False, use total uncertainty (epistemic + aleatoric).</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of uncertainty scores for each pool sample</p>"},{"location":"api/acquisition.html#evidential_uncertainty_sampling","title":"evidential_uncertainty_sampling","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.evidential_uncertainty_sampling","title":"molax.acquisition.uncertainty.evidential_uncertainty_sampling","text":"<pre><code>evidential_uncertainty_sampling(\n    model: EvidentialGCN,\n    pool_graphs: List[GraphsTuple],\n    use_epistemic: bool = True,\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute uncertainty scores for pool samples using evidential prediction.</p> <p>Unlike MC Dropout, evidential models provide uncertainty in a single forward pass by predicting the parameters of a higher-order distribution.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>EvidentialGCN</code> <p>EvidentialGCN model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of jraph.GraphsTuple for pool samples</p> required <code>use_epistemic</code> <code>bool</code> <p>If True, use epistemic uncertainty (model uncertainty).           If False, use total uncertainty (epistemic + aleatoric).</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of uncertainty scores for each pool sample</p>"},{"location":"api/acquisition.html#diversity-based-acquisition","title":"Diversity-based Acquisition","text":"<p>Functions that select diverse samples in feature space.</p>"},{"location":"api/acquisition.html#diversity_sampling","title":"diversity_sampling","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.diversity_sampling","title":"molax.acquisition.uncertainty.diversity_sampling","text":"<pre><code>diversity_sampling(\n    pool_graphs: List[GraphsTuple],\n    labeled_graphs: List[GraphsTuple],\n    n_select: int,\n) -&gt; List[int]\n</code></pre> <p>Select diverse samples using greedy farthest point sampling.</p> <p>Uses mean node features as molecular fingerprints.</p> <p>Parameters:</p> Name Type Description Default <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of pool sample graphs</p> required <code>labeled_graphs</code> <code>List[GraphsTuple]</code> <p>List of labeled sample graphs</p> required <code>n_select</code> <code>int</code> <p>Number of samples to select</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List of selected indices into pool_graphs</p>"},{"location":"api/acquisition.html#combined-acquisition","title":"Combined Acquisition","text":"<p>Functions that combine multiple acquisition strategies.</p>"},{"location":"api/acquisition.html#combined_acquisition","title":"combined_acquisition","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.combined_acquisition","title":"molax.acquisition.uncertainty.combined_acquisition","text":"<pre><code>combined_acquisition(\n    model: UncertaintyGCN,\n    pool_graphs: List[GraphsTuple],\n    labeled_graphs: List[GraphsTuple],\n    n_select: int,\n    uncertainty_weight: float = 0.7,\n    n_mc_samples: int = 10,\n) -&gt; List[int]\n</code></pre> <p>Combined uncertainty and diversity acquisition.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>UncertaintyGCN</code> <p>UncertaintyGCN model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of pool sample graphs</p> required <code>labeled_graphs</code> <code>List[GraphsTuple]</code> <p>List of labeled sample graphs</p> required <code>n_select</code> <code>int</code> <p>Number of samples to select</p> required <code>uncertainty_weight</code> <code>float</code> <p>Weight for uncertainty vs diversity (0-1)</p> <code>0.7</code> <code>n_mc_samples</code> <code>int</code> <p>Number of MC samples for uncertainty estimation</p> <code>10</code> <p>Returns:</p> Type Description <code>List[int]</code> <p>List of selected indices into pool_graphs</p>"},{"location":"api/acquisition.html#combined_ensemble_acquisition","title":"combined_ensemble_acquisition","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.combined_ensemble_acquisition","title":"molax.acquisition.uncertainty.combined_ensemble_acquisition","text":"<pre><code>combined_ensemble_acquisition(\n    ensemble: DeepEnsemble,\n    pool_graphs: List[GraphsTuple],\n    labeled_graphs: List[GraphsTuple],\n    n_select: int,\n    uncertainty_weight: float = 0.7,\n    use_epistemic: bool = True,\n) -&gt; List[int]\n</code></pre> <p>Combined uncertainty and diversity acquisition using ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>DeepEnsemble</code> <p>DeepEnsemble model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of pool sample graphs</p> required <code>labeled_graphs</code> <code>List[GraphsTuple]</code> <p>List of labeled sample graphs</p> required <code>n_select</code> <code>int</code> <p>Number of samples to select</p> required <code>uncertainty_weight</code> <code>float</code> <p>Weight for uncertainty vs diversity (0-1)</p> <code>0.7</code> <code>use_epistemic</code> <code>bool</code> <p>If True, use epistemic uncertainty for acquisition</p> <code>True</code> <p>Returns:</p> Type Description <code>List[int]</code> <p>List of selected indices into pool_graphs</p>"},{"location":"api/acquisition.html#combined_evidential_acquisition","title":"combined_evidential_acquisition","text":""},{"location":"api/acquisition.html#molax.acquisition.uncertainty.combined_evidential_acquisition","title":"molax.acquisition.uncertainty.combined_evidential_acquisition","text":"<pre><code>combined_evidential_acquisition(\n    model: EvidentialGCN,\n    pool_graphs: List[GraphsTuple],\n    labeled_graphs: List[GraphsTuple],\n    n_select: int,\n    uncertainty_weight: float = 0.7,\n    use_epistemic: bool = True,\n) -&gt; List[int]\n</code></pre> <p>Combined uncertainty and diversity acquisition using evidential model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>EvidentialGCN</code> <p>EvidentialGCN model</p> required <code>pool_graphs</code> <code>List[GraphsTuple]</code> <p>List of pool sample graphs</p> required <code>labeled_graphs</code> <code>List[GraphsTuple]</code> <p>List of labeled sample graphs</p> required <code>n_select</code> <code>int</code> <p>Number of samples to select</p> required <code>uncertainty_weight</code> <code>float</code> <p>Weight for uncertainty vs diversity (0-1)</p> <code>0.7</code> <code>use_epistemic</code> <code>bool</code> <p>If True, use epistemic uncertainty for acquisition</p> <code>True</code> <p>Returns:</p> Type Description <code>List[int]</code> <p>List of selected indices into pool_graphs</p>"},{"location":"api/data.html","title":"Data Utilities","text":"<p>This page documents the data loading and processing utilities.</p>"},{"location":"api/data.html#dataset-classes","title":"Dataset Classes","text":""},{"location":"api/data.html#moleculardataset","title":"MolecularDataset","text":""},{"location":"api/data.html#molax.utils.data.MolecularDataset","title":"molax.utils.data.MolecularDataset","text":"<p>Dataset class for molecular graphs using jraph format.</p> <p>Attributes:</p> Name Type Description <code>graphs</code> <code>List[GraphsTuple]</code> <p>List of jraph.GraphsTuple objects</p> <code>labels</code> <code>List[float]</code> <p>Array of property labels</p> <code>n_node_features</code> <p>Number of node features</p>"},{"location":"api/data.html#molax.utils.data.MolecularDataset.__init__","title":"__init__","text":"<pre><code>__init__(\n    data: Union[DataFrame, str, Path],\n    smiles_col: str = \"smiles\",\n    label_col: str = \"property\",\n)\n</code></pre> <p>Initialize dataset from DataFrame or CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, str, Path]</code> <p>DataFrame or path to CSV file</p> required <code>smiles_col</code> <code>str</code> <p>Column name for SMILES strings</p> <code>'smiles'</code> <code>label_col</code> <code>str</code> <p>Column name for property labels</p> <code>'property'</code>"},{"location":"api/data.html#molax.utils.data.MolecularDataset.get_batched","title":"get_batched","text":"<pre><code>get_batched(\n    indices: Optional[List[int]] = None,\n    pad_to_nodes: Optional[int] = None,\n    pad_to_edges: Optional[int] = None,\n    pad_to_graphs: Optional[int] = None,\n) -&gt; Tuple[jraph.GraphsTuple, jnp.ndarray]\n</code></pre> <p>Get a batched GraphsTuple for the specified indices.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>Optional[List[int]]</code> <p>List of indices to include. If None, returns all data.</p> <code>None</code> <code>pad_to_nodes</code> <code>Optional[int]</code> <p>Pad to this many nodes for consistent JIT shapes</p> <code>None</code> <code>pad_to_edges</code> <code>Optional[int]</code> <p>Pad to this many edges</p> <code>None</code> <code>pad_to_graphs</code> <code>Optional[int]</code> <p>Pad to this many graphs</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[GraphsTuple, ndarray]</code> <p>Tuple of (batched_graphs, labels)</p>"},{"location":"api/data.html#molax.utils.data.MolecularDataset.compute_padding_sizes","title":"compute_padding_sizes","text":"<pre><code>compute_padding_sizes(batch_size: int) -&gt; Tuple[int, int, int]\n</code></pre> <p>Compute fixed padding sizes for efficient JIT compilation.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Maximum batch size</p> required <p>Returns:</p> Type Description <code>Tuple[int, int, int]</code> <p>Tuple of (max_nodes, max_edges, n_graphs) for padding</p>"},{"location":"api/data.html#molax.utils.data.MolecularDataset.split","title":"split","text":"<pre><code>split(\n    test_size: float = 0.2, seed: Optional[int] = None\n) -&gt; Tuple[MolecularDataset, MolecularDataset]\n</code></pre> <p>Split dataset into train and test sets.</p> <p>Parameters:</p> Name Type Description Default <code>test_size</code> <code>float</code> <p>Fraction for test set</p> <code>0.2</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed for reproducibility</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[MolecularDataset, MolecularDataset]</code> <p>Tuple of (train_dataset, test_dataset)</p>"},{"location":"api/data.html#graph-conversion","title":"Graph Conversion","text":"<p>Functions for converting molecular representations to graph format.</p>"},{"location":"api/data.html#smiles_to_jraph","title":"smiles_to_jraph","text":""},{"location":"api/data.html#molax.utils.data.smiles_to_jraph","title":"molax.utils.data.smiles_to_jraph","text":"<pre><code>smiles_to_jraph(smiles: str) -&gt; jraph.GraphsTuple\n</code></pre> <p>Convert SMILES string to jraph GraphsTuple format.</p> <p>Parameters:</p> Name Type Description Default <code>smiles</code> <code>str</code> <p>SMILES string representing the molecule</p> required <p>Returns:</p> Type Description <code>GraphsTuple</code> <p>jraph.GraphsTuple containing the molecular graph</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the SMILES string is invalid</p>"},{"location":"api/data.html#batch_graphs","title":"batch_graphs","text":""},{"location":"api/data.html#molax.utils.data.batch_graphs","title":"molax.utils.data.batch_graphs","text":"<pre><code>batch_graphs(\n    graphs: List[GraphsTuple],\n    pad_to_nodes: Optional[int] = None,\n    pad_to_edges: Optional[int] = None,\n    pad_to_graphs: Optional[int] = None,\n) -&gt; jraph.GraphsTuple\n</code></pre> <p>Batch multiple graphs into a single padded GraphsTuple.</p> <p>Padding ensures consistent shapes for JIT compilation efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>graphs</code> <code>List[GraphsTuple]</code> <p>List of individual GraphsTuple objects</p> required <code>pad_to_nodes</code> <code>Optional[int]</code> <p>Pad total nodes to this number (default: auto)</p> <code>None</code> <code>pad_to_edges</code> <code>Optional[int]</code> <p>Pad total edges to this number (default: auto)</p> <code>None</code> <code>pad_to_graphs</code> <code>Optional[int]</code> <p>Pad to this many graphs (default: len(graphs) + 1)</p> <code>None</code> <p>Returns:</p> Type Description <code>GraphsTuple</code> <p>Single batched and padded GraphsTuple</p>"},{"location":"api/data.html#unbatch_graphs","title":"unbatch_graphs","text":""},{"location":"api/data.html#molax.utils.data.unbatch_graphs","title":"molax.utils.data.unbatch_graphs","text":"<pre><code>unbatch_graphs(batched: GraphsTuple) -&gt; List[jraph.GraphsTuple]\n</code></pre> <p>Unbatch a batched GraphsTuple back to individual graphs.</p> <p>Parameters:</p> Name Type Description Default <code>batched</code> <code>GraphsTuple</code> <p>Batched GraphsTuple</p> required <p>Returns:</p> Type Description <code>List[GraphsTuple]</code> <p>List of individual GraphsTuple objects</p>"},{"location":"api/metrics.html","title":"Calibration Metrics","text":"<p>This page documents the uncertainty calibration metrics and visualization tools.</p>"},{"location":"api/metrics.html#calibration-metrics_1","title":"Calibration Metrics","text":""},{"location":"api/metrics.html#expected_calibration_error","title":"expected_calibration_error","text":""},{"location":"api/metrics.html#molax.metrics.calibration.expected_calibration_error","title":"molax.metrics.calibration.expected_calibration_error","text":"<pre><code>expected_calibration_error(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    n_bins: int = 10,\n    mask: Optional[ndarray] = None,\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute Expected Calibration Error (ECE) for regression.</p> <p>ECE measures the average gap between expected and observed confidence across different confidence levels. Perfect calibration = 0.</p> <p>For regression: ECE = mean(|observed_coverage - expected_coverage|)</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>n_bins</code> <code>int</code> <p>Number of confidence level bins (default: 10)</p> <code>10</code> <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Scalar ECE value in [0, 1]. Lower is better.</p>"},{"location":"api/metrics.html#negative_log_likelihood","title":"negative_log_likelihood","text":""},{"location":"api/metrics.html#molax.metrics.calibration.negative_log_likelihood","title":"molax.metrics.calibration.negative_log_likelihood","text":"<pre><code>negative_log_likelihood(\n    mean: ndarray,\n    var: ndarray,\n    targets: ndarray,\n    mask: Optional[ndarray] = None,\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute Gaussian negative log-likelihood (proper scoring rule).</p> <p>NLL = 0.5 * (log(2pivar) + (y - mean)^2 / var)</p> <p>Lower is better. This is the proper scoring rule for probabilistic predictions with Gaussian likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>ndarray</code> <p>Predicted means of shape [n_samples] or [n_samples, 1]</p> required <code>var</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples] or [n_samples, 1]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples] or [n_samples, 1]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples (True = include)</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Scalar NLL value (mean over valid samples)</p>"},{"location":"api/metrics.html#compute_calibration_curve","title":"compute_calibration_curve","text":""},{"location":"api/metrics.html#molax.metrics.calibration.compute_calibration_curve","title":"molax.metrics.calibration.compute_calibration_curve","text":"<pre><code>compute_calibration_curve(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    n_bins: int = 10,\n    mask: Optional[ndarray] = None,\n) -&gt; Dict[str, jnp.ndarray]\n</code></pre> <p>Compute data for reliability diagrams.</p> <p>For regression with Gaussian uncertainty, we compute calibration by checking what fraction of targets fall within various confidence intervals.</p> <p>For each confidence level p (e.g., 50%, 68%, 90%, 95%): - Compute interval: [mean - z_p * std, mean + z_p * std] - Count fraction of targets within interval (observed coverage) - Perfect calibration: observed coverage = expected coverage</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>n_bins</code> <code>int</code> <p>Number of confidence level bins (default: 10)</p> <code>10</code> <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary with:</p> <code>Dict[str, ndarray]</code> <ul> <li>expected_coverage: Expected confidence levels (bin centers)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>observed_coverage: Actual fraction of targets within interval</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>bin_counts: Number of samples per bin (all same for regression)</li> </ul>"},{"location":"api/metrics.html#sharpness","title":"sharpness","text":""},{"location":"api/metrics.html#molax.metrics.calibration.sharpness","title":"molax.metrics.calibration.sharpness","text":"<pre><code>sharpness(\n    uncertainties: ndarray, mask: Optional[ndarray] = None\n) -&gt; jnp.ndarray\n</code></pre> <p>Compute sharpness (average predicted uncertainty).</p> <p>Sharpness measures how confident the model is on average. Lower = sharper/more confident predictions.</p> <p>Note: Sharpness alone doesn't indicate quality - a model can be overconfidently wrong. Use together with calibration metrics.</p> <p>Parameters:</p> Name Type Description Default <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Scalar mean standard deviation</p>"},{"location":"api/metrics.html#evaluate_calibration","title":"evaluate_calibration","text":""},{"location":"api/metrics.html#molax.metrics.calibration.evaluate_calibration","title":"molax.metrics.calibration.evaluate_calibration","text":"<pre><code>evaluate_calibration(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    mask: Optional[ndarray] = None,\n    n_bins: int = 10,\n) -&gt; Dict[str, float]\n</code></pre> <p>Compute comprehensive calibration metrics.</p> <p>Convenience function that computes all calibration metrics at once.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <code>n_bins</code> <code>int</code> <p>Number of bins for ECE computation</p> <code>10</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary with:</p> <code>Dict[str, float]</code> <ul> <li>nll: Negative log-likelihood</li> </ul> <code>Dict[str, float]</code> <ul> <li>ece: Expected calibration error</li> </ul> <code>Dict[str, float]</code> <ul> <li>rmse: Root mean squared error</li> </ul> <code>Dict[str, float]</code> <ul> <li>sharpness: Average predicted std</li> </ul> <code>Dict[str, float]</code> <ul> <li>mean_z_score: Mean |z-score| (should be ~0.8 for calibrated)</li> </ul>"},{"location":"api/metrics.html#post-hoc-calibration","title":"Post-hoc Calibration","text":""},{"location":"api/metrics.html#temperaturescaling","title":"TemperatureScaling","text":""},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling","title":"molax.metrics.calibration.TemperatureScaling","text":"<p>Temperature scaling for post-hoc calibration.</p> Temperature scaling learns a single parameter T to scale uncertainties <p>calibrated_variance = T * predicted_variance</p> <p>T &gt; 1 increases uncertainty (model is overconfident) T &lt; 1 decreases uncertainty (model is underconfident)</p> <p>The temperature is optimized to minimize NLL on a validation set.</p> Usage <p>scaler = TemperatureScaling() scaler.fit(val_predictions, val_uncertainties, val_targets) calibrated_var = scaler.transform(test_uncertainties)</p> <p>Reference: Guo et al., \"On Calibration of Modern Neural Networks\", ICML 2017</p>"},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling.temperature","title":"temperature  <code>property</code>","text":"<pre><code>temperature: float\n</code></pre> <p>Get learned temperature value.</p>"},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling.is_fitted","title":"is_fitted  <code>property</code>","text":"<pre><code>is_fitted: bool\n</code></pre> <p>Check if the scaler has been fitted.</p>"},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize temperature scaler with T=1 (no scaling).</p>"},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling.fit","title":"fit","text":"<pre><code>fit(\n    val_predictions: ndarray,\n    val_uncertainties: ndarray,\n    val_targets: ndarray,\n    mask: Optional[ndarray] = None,\n    max_iter: int = 100,\n    lr: float = 0.1,\n) -&gt; TemperatureScaling\n</code></pre> <p>Optimize temperature on validation data.</p> <p>Uses gradient descent to minimize NLL with respect to temperature.</p> <p>Parameters:</p> Name Type Description Default <code>val_predictions</code> <code>ndarray</code> <p>Validation predictions of shape [n_val]</p> required <code>val_uncertainties</code> <code>ndarray</code> <p>Validation variances of shape [n_val]</p> required <code>val_targets</code> <code>ndarray</code> <p>Validation targets of shape [n_val]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <code>max_iter</code> <code>int</code> <p>Maximum optimization iterations</p> <code>100</code> <code>lr</code> <code>float</code> <p>Learning rate for gradient descent</p> <code>0.1</code> <p>Returns:</p> Type Description <code>TemperatureScaling</code> <p>Self for method chaining</p>"},{"location":"api/metrics.html#molax.metrics.calibration.TemperatureScaling.transform","title":"transform","text":"<pre><code>transform(uncertainties: ndarray) -&gt; jnp.ndarray\n</code></pre> <p>Apply learned temperature scaling to uncertainties.</p> <p>Parameters:</p> Name Type Description Default <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Scaled variances: T * uncertainties</p>"},{"location":"api/metrics.html#visualization","title":"Visualization","text":""},{"location":"api/metrics.html#plot_reliability_diagram","title":"plot_reliability_diagram","text":""},{"location":"api/metrics.html#molax.metrics.visualization.plot_reliability_diagram","title":"molax.metrics.visualization.plot_reliability_diagram","text":"<pre><code>plot_reliability_diagram(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    n_bins: int = 10,\n    mask: Optional[ndarray] = None,\n    ax: Optional[Axes] = None,\n    title: str = \"Reliability Diagram\",\n    color: str = \"steelblue\",\n    show_ece: bool = True,\n) -&gt; plt.Axes\n</code></pre> <p>Plot reliability diagram showing calibration quality.</p> <p>A reliability diagram visualizes how well-calibrated uncertainty estimates are. The x-axis shows expected confidence (coverage), and the y-axis shows observed confidence (actual coverage).</p> <p>Perfect calibration: points lie on the diagonal (y = x). Above diagonal: underconfident (uncertainties too high) Below diagonal: overconfident (uncertainties too low)</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>n_bins</code> <code>int</code> <p>Number of confidence level bins</p> <code>10</code> <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib Axes. Creates new figure if None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title</p> <code>'Reliability Diagram'</code> <code>color</code> <code>str</code> <p>Color for the calibration curve</p> <code>'steelblue'</code> <code>show_ece</code> <code>bool</code> <p>Whether to display ECE value in legend</p> <code>True</code> <p>Returns:</p> Type Description <code>Axes</code> <p>matplotlib Axes object</p>"},{"location":"api/metrics.html#plot_calibration_comparison","title":"plot_calibration_comparison","text":""},{"location":"api/metrics.html#molax.metrics.visualization.plot_calibration_comparison","title":"molax.metrics.visualization.plot_calibration_comparison","text":"<pre><code>plot_calibration_comparison(\n    results: Dict[str, Tuple[ndarray, ndarray, ndarray]],\n    n_bins: int = 10,\n    figsize: Tuple[int, int] = (12, 5),\n    colors: Optional[Dict[str, str]] = None,\n) -&gt; plt.Figure\n</code></pre> <p>Compare calibration across multiple models.</p> <p>Creates a figure with two subplots: 1. Reliability diagrams for all models overlaid 2. Bar chart comparing ECE values</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Dict[str, Tuple[ndarray, ndarray, ndarray]]</code> <p>Dictionary mapping model names to tuples of     (predictions, uncertainties, targets)</p> required <code>n_bins</code> <code>int</code> <p>Number of bins for calibration computation</p> <code>10</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Figure size as (width, height)</p> <code>(12, 5)</code> <code>colors</code> <code>Optional[Dict[str, str]]</code> <p>Optional dictionary mapping model names to colors</p> <code>None</code> <p>Returns:</p> Type Description <code>Figure</code> <p>matplotlib Figure object</p>"},{"location":"api/metrics.html#plot_uncertainty_vs_error","title":"plot_uncertainty_vs_error","text":""},{"location":"api/metrics.html#molax.metrics.visualization.plot_uncertainty_vs_error","title":"molax.metrics.visualization.plot_uncertainty_vs_error","text":"<pre><code>plot_uncertainty_vs_error(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    mask: Optional[ndarray] = None,\n    ax: Optional[Axes] = None,\n    title: str = \"Uncertainty vs Error\",\n    color: str = \"steelblue\",\n    show_correlation: bool = True,\n) -&gt; plt.Axes\n</code></pre> <p>Scatter plot of predicted uncertainty vs actual error.</p> <p>For well-calibrated models, higher uncertainty should correlate with higher error. Points should cluster around the diagonal.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Optional matplotlib Axes. Creates new figure if None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Plot title</p> <code>'Uncertainty vs Error'</code> <code>color</code> <code>str</code> <p>Color for scatter points</p> <code>'steelblue'</code> <code>show_correlation</code> <code>bool</code> <p>Whether to display Pearson correlation</p> <code>True</code> <p>Returns:</p> Type Description <code>Axes</code> <p>matplotlib Axes object</p>"},{"location":"api/metrics.html#create_calibration_report","title":"create_calibration_report","text":""},{"location":"api/metrics.html#molax.metrics.visualization.create_calibration_report","title":"molax.metrics.visualization.create_calibration_report","text":"<pre><code>create_calibration_report(\n    predictions: ndarray,\n    uncertainties: ndarray,\n    targets: ndarray,\n    mask: Optional[ndarray] = None,\n    model_name: str = \"Model\",\n    figsize: Tuple[int, int] = (14, 10),\n) -&gt; plt.Figure\n</code></pre> <p>Create a comprehensive calibration report with multiple plots.</p> <p>Generates a figure with four subplots: 1. Reliability diagram 2. Uncertainty vs error scatter 3. Uncertainty histogram 4. Z-score histogram</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>Predicted means of shape [n_samples]</p> required <code>uncertainties</code> <code>ndarray</code> <p>Predicted variances of shape [n_samples]</p> required <code>targets</code> <code>ndarray</code> <p>True values of shape [n_samples]</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>Optional boolean mask for valid samples</p> <code>None</code> <code>model_name</code> <code>str</code> <p>Name of the model for titles</p> <code>'Model'</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Figure size as (width, height)</p> <code>(14, 10)</code> <p>Returns:</p> Type Description <code>Figure</code> <p>matplotlib Figure object</p>"},{"location":"api/models.html","title":"Models API","text":"<p>This page documents the neural network models available in molax for molecular property prediction with uncertainty quantification.</p>"},{"location":"api/models.html#gcn-models","title":"GCN Models","text":"<p>The core Graph Convolutional Network models with MC Dropout uncertainty.</p>"},{"location":"api/models.html#gcnconfig","title":"GCNConfig","text":""},{"location":"api/models.html#molax.models.gcn.GCNConfig","title":"molax.models.gcn.GCNConfig  <code>dataclass</code>","text":"<p>Configuration for Graph Convolutional Network.</p> <p>Attributes:</p> Name Type Description <code>node_features</code> <code>int</code> <p>Input node feature dimension</p> <code>hidden_features</code> <code>Sequence[int]</code> <p>List of hidden layer dimensions</p> <code>out_features</code> <code>int</code> <p>Output dimension</p> <code>dropout_rate</code> <code>float</code> <p>Dropout rate for regularization</p>"},{"location":"api/models.html#uncertaintygcn","title":"UncertaintyGCN","text":""},{"location":"api/models.html#molax.models.gcn.UncertaintyGCN","title":"molax.models.gcn.UncertaintyGCN","text":"<p>               Bases: <code>Module</code></p> <p>GCN with uncertainty estimation via mean and variance heads.</p> <p>Outputs both mean prediction and predicted variance for uncertainty quantification.</p>"},{"location":"api/models.html#molax.models.gcn.UncertaintyGCN.__call__","title":"__call__","text":"<pre><code>__call__(\n    graph: GraphsTuple, training: bool = False\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray]\n</code></pre> <p>Forward pass returning mean and variance.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched (and possibly padded) jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of (mean, variance) each of shape [n_graphs, out_features]</p>"},{"location":"api/models.html#molax.models.gcn.UncertaintyGCN.extract_embeddings","title":"extract_embeddings","text":"<pre><code>extract_embeddings(graph: GraphsTuple, training: bool = False) -&gt; jnp.ndarray\n</code></pre> <p>Extract penultimate layer embeddings (graph-level).</p> <p>Extracts the pooled graph representations before the output heads, which can be used for Core-Set selection, DPP sampling, or other embedding-based acquisition strategies.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode (enables dropout)</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Embeddings of shape [n_graphs, hidden_dim] where hidden_dim</p> <code>ndarray</code> <p>is the last element of hidden_features in the config.</p>"},{"location":"api/models.html#moleculargcn","title":"MolecularGCN","text":""},{"location":"api/models.html#molax.models.gcn.MolecularGCN","title":"molax.models.gcn.MolecularGCN","text":"<p>               Bases: <code>Module</code></p> <p>Graph Convolutional Network for molecular property prediction.</p> <p>Uses jraph for efficient batched processing of variable-sized graphs.</p>"},{"location":"api/models.html#molax.models.gcn.MolecularGCN.__call__","title":"__call__","text":"<pre><code>__call__(graph: GraphsTuple, training: bool = False) -&gt; jnp.ndarray\n</code></pre> <p>Forward pass through the GCN.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched (and possibly padded) jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode (enables dropout)</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Graph-level predictions of shape [n_graphs, out_features]</p>"},{"location":"api/models.html#deep-ensembles","title":"Deep Ensembles","text":"<p>Ensemble methods for improved uncertainty quantification through model disagreement.</p>"},{"location":"api/models.html#ensembleconfig","title":"EnsembleConfig","text":""},{"location":"api/models.html#molax.models.ensemble.EnsembleConfig","title":"molax.models.ensemble.EnsembleConfig  <code>dataclass</code>","text":"<p>Configuration for Deep Ensemble.</p> <p>Attributes:</p> Name Type Description <code>base_config</code> <code>GCNConfig</code> <p>Configuration for each ensemble member (GCNConfig)</p> <code>n_members</code> <code>int</code> <p>Number of ensemble members (default: 5)</p>"},{"location":"api/models.html#deepensemble","title":"DeepEnsemble","text":""},{"location":"api/models.html#molax.models.ensemble.DeepEnsemble","title":"molax.models.ensemble.DeepEnsemble","text":"<p>               Bases: <code>Module</code></p> <p>Deep Ensemble of UncertaintyGCN models.</p> <p>Trains N independent GCN models with different random initializations. Provides improved uncertainty estimation by decomposing into: - Epistemic uncertainty: disagreement between models (reducible with more data) - Aleatoric uncertainty: average predicted variance (inherent noise)</p>"},{"location":"api/models.html#molax.models.ensemble.DeepEnsemble.__init__","title":"__init__","text":"<pre><code>__init__(config: EnsembleConfig, rngs: Rngs)\n</code></pre> <p>Initialize ensemble with N independent models.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EnsembleConfig</code> <p>EnsembleConfig with base model config and n_members</p> required <code>rngs</code> <code>Rngs</code> <p>Random number generators for initialization</p> required"},{"location":"api/models.html#molax.models.ensemble.DeepEnsemble.__call__","title":"__call__","text":"<pre><code>__call__(\n    graph: GraphsTuple, training: bool = False\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]\n</code></pre> <p>Forward pass returning mean, total uncertainty, and epistemic uncertainty.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple of:</p> <code>ndarray</code> <ul> <li>ensemble_mean: Mean prediction across all members</li> </ul> <code>ndarray</code> <ul> <li>total_var: Total uncertainty (epistemic + aleatoric)</li> </ul> <code>Tuple[ndarray, ndarray, ndarray]</code> <ul> <li>epistemic_var: Epistemic uncertainty (model disagreement)</li> </ul> <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Each has shape [n_graphs, out_features].</p>"},{"location":"api/models.html#molax.models.ensemble.DeepEnsemble.predict_member","title":"predict_member","text":"<pre><code>predict_member(\n    member_idx: int, graph: GraphsTuple, training: bool = False\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray]\n</code></pre> <p>Get prediction from a specific ensemble member.</p> <p>Parameters:</p> Name Type Description Default <code>member_idx</code> <code>int</code> <p>Index of the ensemble member (0 to n_members-1)</p> required <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of (mean, variance) from the specified member</p>"},{"location":"api/models.html#molax.models.ensemble.DeepEnsemble.extract_embeddings","title":"extract_embeddings","text":"<pre><code>extract_embeddings(graph: GraphsTuple, training: bool = False) -&gt; jnp.ndarray\n</code></pre> <p>Extract averaged embeddings from all ensemble members.</p> <p>Each member extracts embeddings independently, and the results are averaged to produce a single embedding per graph. This can be used for Core-Set selection, DPP sampling, or other embedding-based acquisition strategies.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Averaged embeddings of shape [n_graphs, hidden_dim]</p>"},{"location":"api/models.html#evidential-deep-learning","title":"Evidential Deep Learning","text":"<p>Single-pass uncertainty estimation using evidential neural networks.</p>"},{"location":"api/models.html#evidentialconfig","title":"EvidentialConfig","text":""},{"location":"api/models.html#molax.models.evidential.EvidentialConfig","title":"molax.models.evidential.EvidentialConfig  <code>dataclass</code>","text":"<p>Configuration for Evidential GCN.</p> <p>Attributes:</p> Name Type Description <code>base_config</code> <code>GCNConfig</code> <p>Configuration for the GCN backbone (GCNConfig)</p> <code>lambda_reg</code> <code>float</code> <p>Regularization weight for evidence on errors (default: 0.1)</p>"},{"location":"api/models.html#evidentialgcn","title":"EvidentialGCN","text":""},{"location":"api/models.html#molax.models.evidential.EvidentialGCN","title":"molax.models.evidential.EvidentialGCN","text":"<p>               Bases: <code>Module</code></p> <p>GCN with Evidential Deep Learning for uncertainty quantification.</p> <p>Uses a GCN backbone followed by an evidential head that predicts Normal-Inverse-Gamma parameters, enabling single-pass uncertainty estimation with separation of aleatoric and epistemic components.</p>"},{"location":"api/models.html#molax.models.evidential.EvidentialGCN.__init__","title":"__init__","text":"<pre><code>__init__(config: EvidentialConfig, rngs: Rngs)\n</code></pre> <p>Initialize EvidentialGCN.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>EvidentialConfig</code> <p>EvidentialConfig with base model config and lambda_reg</p> required <code>rngs</code> <code>Rngs</code> <p>Random number generators for initialization</p> required"},{"location":"api/models.html#molax.models.evidential.EvidentialGCN.forward_raw","title":"forward_raw","text":"<pre><code>forward_raw(\n    graph: GraphsTuple, training: bool = False\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray, jnp.ndarray]\n</code></pre> <p>Forward pass returning raw NIG parameters.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple of (gamma, nu, alpha, beta) - NIG parameters</p> <code>ndarray</code> <p>Each has shape [n_graphs, 1]</p>"},{"location":"api/models.html#molax.models.evidential.EvidentialGCN.__call__","title":"__call__","text":"<pre><code>__call__(\n    graph: GraphsTuple, training: bool = False\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]\n</code></pre> <p>Forward pass returning mean, total uncertainty, and epistemic uncertainty.</p> <p>This signature matches DeepEnsemble for drop-in replacement.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple of:</p> <code>ndarray</code> <ul> <li>mean: Mean prediction [n_graphs, 1]</li> </ul> <code>ndarray</code> <ul> <li>total_var: Total uncertainty (aleatoric + epistemic) [n_graphs, 1]</li> </ul> <code>Tuple[ndarray, ndarray, ndarray]</code> <ul> <li>epistemic_var: Epistemic uncertainty [n_graphs, 1]</li> </ul>"},{"location":"api/models.html#molax.models.evidential.EvidentialGCN.extract_embeddings","title":"extract_embeddings","text":"<pre><code>extract_embeddings(graph: GraphsTuple, training: bool = False) -&gt; jnp.ndarray\n</code></pre> <p>Extract penultimate layer embeddings (graph-level).</p> <p>Extracts the pooled graph representations before the evidential head, which can be used for Core-Set selection, DPP sampling, or other embedding-based acquisition strategies.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>GraphsTuple</code> <p>Batched jraph.GraphsTuple</p> required <code>training</code> <code>bool</code> <p>Whether in training mode (enables dropout)</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Embeddings of shape [n_graphs, hidden_dim] where hidden_dim</p> <code>ndarray</code> <p>is the last element of hidden_features in the config.</p>"},{"location":"api/models.html#training-utilities","title":"Training Utilities","text":""},{"location":"api/models.html#molax.models.gcn.train_step","title":"molax.models.gcn.train_step","text":"<pre><code>train_step(\n    model: UncertaintyGCN,\n    optimizer: Optimizer,\n    graph: GraphsTuple,\n    labels: ndarray,\n    mask: ndarray,\n) -&gt; jnp.ndarray\n</code></pre> <p>JIT-compiled training step.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>UncertaintyGCN</code> <p>The model</p> required <code>optimizer</code> <code>Optimizer</code> <p>The optimizer</p> required <code>graph</code> <code>GraphsTuple</code> <p>Batched (padded) input graphs</p> required <code>labels</code> <code>ndarray</code> <p>Target labels of shape [n_graphs] (padded with zeros)</p> required <code>mask</code> <code>ndarray</code> <p>Boolean mask indicating real graphs (not padding)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Loss value</p>"},{"location":"api/models.html#molax.models.gcn.eval_step","title":"molax.models.gcn.eval_step","text":"<pre><code>eval_step(\n    model: UncertaintyGCN, graph: GraphsTuple, labels: ndarray, mask: ndarray\n) -&gt; Tuple[jnp.ndarray, jnp.ndarray]\n</code></pre> <p>JIT-compiled evaluation step.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>UncertaintyGCN</code> <p>The model</p> required <code>graph</code> <code>GraphsTuple</code> <p>Batched (padded) input graphs</p> required <code>labels</code> <code>ndarray</code> <p>Target labels (padded)</p> required <code>mask</code> <code>ndarray</code> <p>Boolean mask for real graphs</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of (mse, mean_predictions)</p>"}]}